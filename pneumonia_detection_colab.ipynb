{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü©∫ Pneumonia Detection from Chest X-Ray Images\n",
    "## Deep Learning with EfficientNetB0 Transfer Learning\n",
    "\n",
    "This notebook trains a pneumonia detection model using chest X-ray images.\n",
    "\n",
    "### Instructions:\n",
    "1. Upload your dataset ZIP file (archive.zip) to Colab\n",
    "2. Run all cells in order\n",
    "3. Download the trained model at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload & Extract Dataset\n",
    "\n",
    "Upload your `archive.zip` file containing the chest X-ray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "from google.colab import files\n",
    "print(\"üì§ Please upload your archive.zip file:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "zip_file = list(uploaded.keys())[0]\n",
    "print(f\"üì¶ Extracting {zip_file}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')\n",
    "\n",
    "# Find the chest_xray folder\n",
    "for root, dirs, files_list in os.walk('dataset'):\n",
    "    if 'train' in dirs and 'test' in dirs:\n",
    "        DATA_DIR = root\n",
    "        break\n",
    "\n",
    "print(f\"‚úÖ Dataset extracted to: {DATA_DIR}\")\n",
    "print(f\"\\nüìÅ Contents:\")\n",
    "for item in os.listdir(DATA_DIR):\n",
    "    item_path = os.path.join(DATA_DIR, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        count = sum([len(f) for r, d, f in os.walk(item_path)])\n",
    "        print(f\"   {item}/: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "CLASSES = ['NORMAL', 'PNEUMONIA']\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Sample Chest X-Ray Images', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "    images = os.listdir(class_dir)[:4]\n",
    "    \n",
    "    for i, img_name in enumerate(images):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = plt.imread(img_path)\n",
    "        axes[idx, i].imshow(img, cmap='gray')\n",
    "        axes[idx, i].set_title(class_name)\n",
    "        axes[idx, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "train_normal = len(os.listdir(os.path.join(TRAIN_DIR, 'NORMAL')))\n",
    "train_pneumonia = len(os.listdir(os.path.join(TRAIN_DIR, 'PNEUMONIA')))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(CLASSES, [train_normal, train_pneumonia], color=['#2ecc71', '#e74c3c'])\n",
    "plt.title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Number of Images')\n",
    "for i, v in enumerate([train_normal, train_pneumonia]):\n",
    "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Class Distribution:\")\n",
    "print(f\"   NORMAL: {train_normal} images ({train_normal/(train_normal+train_pneumonia)*100:.1f}%)\")\n",
    "print(f\"   PNEUMONIA: {train_pneumonia} images ({train_pneumonia/(train_normal+train_pneumonia)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Generators with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation/Test - only rescaling\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"üìÅ Loading datasets...\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=CLASSES,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=CLASSES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    classes=CLASSES,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"   Training: {train_generator.samples} images\")\n",
    "print(f\"   Validation: {val_generator.samples} images\")\n",
    "print(f\"   Test: {test_generator.samples} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build EfficientNetB0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create EfficientNetB0-based model for pneumonia detection.\"\"\"\n",
    "    print(\"üèóÔ∏è Building EfficientNetB0 model...\")\n",
    "    \n",
    "    # Load pre-trained EfficientNetB0\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build classification head\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall'),\n",
    "                 tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = create_model()\n",
    "\n",
    "print(f\"\\n‚úÖ Model created!\")\n",
    "print(f\"   Total parameters: {model.count_params():,}\")\n",
    "print(f\"   Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training - Phase 1 (Frozen Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "total = train_generator.samples\n",
    "class_counts = np.bincount(train_generator.classes)\n",
    "class_weights = {\n",
    "    0: total / (2 * class_counts[0]),\n",
    "    1: total / (2 * class_counts[1])\n",
    "}\n",
    "print(f\"üìä Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'pneumonia_model_best.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"   PHASE 1: Training with Frozen Base Model\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training - Phase 2 (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"   PHASE 2: Fine-tuning\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Unfreeze top layers of base model\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall'),\n",
    "             tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "print(f\"üîì Trainable parameters after unfreezing: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune training\n",
    "callbacks_list2 = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'pneumonia_model_finetuned.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list2,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories\n",
    "history = {}\n",
    "for key in history1.history:\n",
    "    history[key] = history1.history[key] + history2.history[key]\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].axvline(x=len(history1.history['accuracy'])-1, color='r', linestyle='--', label='Fine-tune start')\n",
    "axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].axvline(x=len(history1.history['loss'])-1, color='r', linestyle='--', label='Fine-tune start')\n",
    "axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"   MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Get predictions\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "y_pred_proba = predictions.flatten()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Model evaluate\n",
    "test_loss, test_acc, test_precision, test_recall, test_auc = model.evaluate(test_generator, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"         FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  ‚úÖ Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  ‚úÖ Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"  ‚úÖ Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"  ‚úÖ F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(f\"  ‚úÖ AUC:       {test_auc:.4f}\")\n",
    "print(f\"  ‚úÖ Loss:      {test_loss:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=CLASSES,\n",
    "    yticklabels=CLASSES,\n",
    "    annot_kws={'size': 20}\n",
    ")\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Confusion Matrix Analysis:\")\n",
    "print(f\"   True Negatives (Normal ‚Üí Normal): {cm[0,0]}\")\n",
    "print(f\"   False Positives (Normal ‚Üí Pneumonia): {cm[0,1]}\")\n",
    "print(f\"   False Negatives (Pneumonia ‚Üí Normal): {cm[1,0]}\")\n",
    "print(f\"   True Positives (Pneumonia ‚Üí Pneumonia): {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in multiple formats\n",
    "model.save('pneumonia_model_final.keras')\n",
    "model.save('pneumonia_model_final.h5')\n",
    "\n",
    "print(\"‚úÖ Model saved as:\")\n",
    "print(\"   - pneumonia_model_final.keras\")\n",
    "print(\"   - pneumonia_model_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation report\n",
    "with open('evaluation_report.txt', 'w') as f:\n",
    "    f.write(\"=\"*60 + \"\\n\")\n",
    "    f.write(\"    PNEUMONIA DETECTION MODEL - EVALUATION REPORT\\n\")\n",
    "    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"PERFORMANCE METRICS\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\\n\")\n",
    "    f.write(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\\n\")\n",
    "    f.write(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\\n\")\n",
    "    f.write(f\"AUC:       {test_auc:.4f}\\n\")\n",
    "    f.write(f\"Loss:      {test_loss:.4f}\\n\\n\")\n",
    "    f.write(\"CLASSIFICATION REPORT\\n\")\n",
    "    f.write(\"-\"*40 + \"\\n\")\n",
    "    f.write(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "\n",
    "print(\"‚úÖ Evaluation report saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip with all results\n",
    "import shutil\n",
    "\n",
    "results_files = [\n",
    "    'pneumonia_model_final.keras',\n",
    "    'pneumonia_model_final.h5',\n",
    "    'confusion_matrix.png',\n",
    "    'roc_curve.png',\n",
    "    'training_history.png',\n",
    "    'sample_images.png',\n",
    "    'class_distribution.png',\n",
    "    'evaluation_report.txt'\n",
    "]\n",
    "\n",
    "with zipfile.ZipFile('pneumonia_detection_results.zip', 'w') as zipf:\n",
    "    for file in results_files:\n",
    "        if os.path.exists(file):\n",
    "            zipf.write(file)\n",
    "\n",
    "print(\"üì¶ Results packaged!\")\n",
    "print(\"\\nüì• Downloading results...\")\n",
    "files.download('pneumonia_detection_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Test Prediction on Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image from test set\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import random\n",
    "\n",
    "# Pick random test image\n",
    "test_class = random.choice(CLASSES)\n",
    "test_images = os.listdir(os.path.join(TEST_DIR, test_class))\n",
    "test_img_name = random.choice(test_images)\n",
    "test_img_path = os.path.join(TEST_DIR, test_class, test_img_name)\n",
    "\n",
    "# Load and preprocess\n",
    "img = image.load_img(test_img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array, verbose=0)[0][0]\n",
    "\n",
    "if prediction > 0.5:\n",
    "    result = \"PNEUMONIA\"\n",
    "    confidence = prediction\n",
    "else:\n",
    "    result = \"NORMAL\"\n",
    "    confidence = 1 - prediction\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image.load_img(test_img_path), cmap='gray')\n",
    "plt.title(f\"Prediction: {result} ({confidence:.1%})\\nActual: {test_class}\", fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüîç Sample Prediction:\")\n",
    "print(f\"   Image: {test_img_name}\")\n",
    "print(f\"   Actual Label: {test_class}\")\n",
    "print(f\"   Predicted: {result}\")\n",
    "print(f\"   Confidence: {confidence:.2%}\")\n",
    "print(f\"   Correct: {'‚úÖ YES' if result == test_class else '‚ùå NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ Training Complete!\n",
    "\n",
    "Your trained model and results have been downloaded. The zip file contains:\n",
    "- `pneumonia_model_final.keras` - Trained model (Keras format)\n",
    "- `pneumonia_model_final.h5` - Trained model (H5 format)\n",
    "- `confusion_matrix.png` - Confusion matrix visualization\n",
    "- `roc_curve.png` - ROC curve plot\n",
    "- `training_history.png` - Training metrics over epochs\n",
    "- `evaluation_report.txt` - Detailed metrics report"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
