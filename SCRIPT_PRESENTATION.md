# ü´Å D√âTECTION DE PNEUMONIE PAR INTELLIGENCE ARTIFICIELLE
## Script de Pr√©sentation Complet

**Projet:** D√©tection Automatique de Pneumonie √† partir de Radiographies Thoraciques  
**Auteur:** Sami Dardar  
**Date:** Janvier 2026

---

# üìñ PARTIE 1: INTRODUCTION (2-3 minutes)

## Slide 1: Titre et Contexte

**√Ä LIRE:**

> "Bonjour √† tous. Aujourd'hui, je vais vous pr√©senter mon projet de d√©tection de pneumonie par intelligence artificielle.
>
> La pneumonie est une infection pulmonaire grave qui touche des millions de personnes chaque ann√©e. C'est l'une des principales causes de mortalit√© infantile dans le monde. Le diagnostic pr√©coce est crucial, mais il n√©cessite l'interpr√©tation de radiographies thoraciques par des m√©decins sp√©cialis√©s, ce qui n'est pas toujours disponible dans les r√©gions d√©favoris√©es.
>
> Mon projet propose une solution: utiliser l'intelligence artificielle pour analyser automatiquement les radiographies et d√©tecter la pr√©sence de pneumonie avec une pr√©cision de pr√®s de 90%."

---

## Slide 2: Objectifs du Projet

**√Ä LIRE:**

> "Les objectifs de ce projet sont les suivants:
>
> **Premi√®rement**, d√©velopper un mod√®le d'apprentissage profond capable de classifier les radiographies thoraciques en deux cat√©gories: NORMAL ou PNEUMONIE.
>
> **Deuxi√®mement**, atteindre une performance √©lev√©e, en particulier un rappel √©lev√©, car il est crucial de ne pas manquer de vrais cas de pneumonie.
>
> **Troisi√®mement**, cr√©er une interface web accessible permettant √† n'importe qui de tester le mod√®le en t√©l√©chargeant une image.
>
> **Quatri√®mement**, d√©ployer l'application en ligne pour qu'elle soit accessible partout dans le monde."

---

# üìñ PARTIE 2: TECHNOLOGIE UTILIS√âE (5-7 minutes)

## Slide 3: Qu'est-ce que l'Apprentissage Profond?

**√Ä LIRE:**

> "Avant d'entrer dans les d√©tails techniques, permettez-moi d'expliquer ce qu'est l'apprentissage profond.
>
> L'apprentissage profond, ou Deep Learning en anglais, est une branche de l'intelligence artificielle qui s'inspire du fonctionnement du cerveau humain. Il utilise des r√©seaux de neurones artificiels compos√©s de plusieurs couches - d'o√π le terme 'profond'.
>
> Chaque couche apprend √† reconna√Ætre des caract√©ristiques de plus en plus complexes. Par exemple:
> - La premi√®re couche peut d√©tecter des bords et des contours
> - La deuxi√®me couche combine ces bords pour former des formes
> - Les couches suivantes reconnaissent des textures, des motifs
> - Les derni√®res couches identifient des objets complets
>
> Dans notre cas, le r√©seau apprend √† reconna√Ætre les signes visuels de la pneumonie dans les radiographies."

---

## Slide 4: Les R√©seaux de Neurones Convolutifs (CNN)

**√Ä LIRE:**

> "Pour analyser des images, on utilise un type sp√©cial de r√©seau appel√© CNN - R√©seau de Neurones Convolutif.
>
> Le mot 'convolutif' vient de l'op√©ration math√©matique de convolution. Imaginez un petit filtre qui se d√©place sur l'image et qui d√©tecte des motifs sp√©cifiques √† chaque position.
>
> Un CNN est compos√© de plusieurs types de couches:
>
> **Les couches de convolution**: Elles appliquent des filtres pour d√©tecter des caract√©ristiques comme les bords, les textures, ou les formes.
>
> **Les couches de pooling**: Elles r√©duisent la taille de l'image tout en gardant l'information importante. C'est comme faire un zoom arri√®re.
>
> **Les couches enti√®rement connect√©es**: √Ä la fin du r√©seau, elles prennent toutes les caract√©ristiques d√©tect√©es et font la classification finale."

---

## Slide 5: Pourquoi ResNet18?

**√Ä LIRE:**

> "Pour ce projet, j'ai choisi l'architecture ResNet18. Laissez-moi vous expliquer pourquoi.
>
> ResNet signifie 'R√©seau R√©siduel'. Il a √©t√© cr√©√© par Microsoft Research en 2015 et a r√©volutionn√© l'apprentissage profond en r√©solvant un probl√®me majeur: le probl√®me du gradient qui dispara√Æt.
>
> Dans les r√©seaux tr√®s profonds, quand on entra√Æne le mod√®le, le signal d'erreur doit se propager √† travers toutes les couches. Dans les anciens r√©seaux, ce signal s'affaiblissait tellement qu'il ne permettait plus d'entra√Æner les premi√®res couches.
>
> ResNet r√©sout ce probl√®me avec des 'connexions de saut'. Ces connexions permettent au signal de passer directement d'une couche √† une autre plus loin, sans s'affaiblir.
>
> Le '18' dans ResNet18 indique que le r√©seau a 18 couches. C'est un bon compromis entre performance et vitesse - assez puissant pour notre t√¢che, mais pas trop lourd √† ex√©cuter."

---

## Slide 6: L'Apprentissage par Transfert

**√Ä LIRE:**

> "Un autre concept cl√© de ce projet est l'apprentissage par transfert.
>
> Entra√Æner un r√©seau de neurones depuis z√©ro n√©cessite des millions d'images et des semaines de calcul. Nous n'avons pas autant de radiographies m√©dicales.
>
> L'id√©e de l'apprentissage par transfert est simple mais puissante: prendre un mod√®le d√©j√† entra√Æn√© sur un grand jeu de donn√©es, comme ImageNet qui contient 1.2 million d'images de 1000 cat√©gories, et le r√©utiliser pour notre t√¢che.
>
> Les premi√®res couches du r√©seau ont d√©j√† appris √† reconna√Ætre des caract√©ristiques g√©n√©rales comme les bords, les textures, les formes. Ces connaissances sont utiles pour n'importe quelle t√¢che d'image, y compris l'analyse m√©dicale.
>
> On garde donc ces couches 'gel√©es' - on ne les modifie pas - et on remplace seulement la derni√®re couche pour l'adapter √† notre probl√®me de classification binaire: Normal ou Pneumonie.
>
> Cette technique nous permet d'obtenir d'excellents r√©sultats avec seulement quelques milliers d'images au lieu de millions."

---

## Slide 7: Architecture du Mod√®le

**√Ä LIRE:**

> "Voici l'architecture exacte de notre mod√®le:
>
> Nous partons de ResNet18 pr√©-entra√Æn√©. Les premi√®res couches restent gel√©es - elles gardent leurs poids d'ImageNet.
>
> Nous rempla√ßons la derni√®re couche, appel√©e 'fully connected' ou FC, par notre propre t√™te de classification. Voici ce qu'elle contient:
>
> **Dropout 50%**: Pendant l'entra√Ænement, on d√©sactive al√©atoirement la moiti√© des neurones. Cela force le r√©seau √† ne pas trop se fier √† des neurones sp√©cifiques et rend le mod√®le plus robuste.
>
> **Couche lin√©aire 512‚Üí256**: On passe de 512 caract√©ristiques √† 256. C'est une r√©duction de dimensionnalit√©.
>
> **Fonction ReLU**: L'activation ReLU, qui signifie Rectified Linear Unit, garde les valeurs positives et met les n√©gatives √† z√©ro. Cela ajoute de la non-lin√©arit√© au r√©seau.
>
> **Dropout 30%**: Une autre couche de r√©gularisation, mais moins agressive.
>
> **Couche lin√©aire 256‚Üí1**: On r√©duit √† une seule valeur.
>
> **Fonction Sigmoid**: Elle convertit cette valeur en une probabilit√© entre 0 et 1. Proche de 0 signifie Normal, proche de 1 signifie Pneumonie."

---

# üìñ PARTIE 3: JEU DE DONN√âES (3-4 minutes)

## Slide 8: Description du Jeu de Donn√©es

**√Ä LIRE:**

> "Pour entra√Æner notre mod√®le, nous avons utilis√© le jeu de donn√©es 'Chest X-Ray Images' disponible sur Kaggle.
>
> Ce jeu de donn√©es contient des radiographies thoraciques d'enfants de 1 √† 5 ans, collect√©es au Guangzhou Women and Children's Medical Center en Chine.
>
> Il est divis√© en trois ensembles:
>
> **L'ensemble d'entra√Ænement**: 5,216 images utilis√©es pour apprendre les patterns. Il contient 1,341 images normales et 3,875 images de pneumonie.
>
> **L'ensemble de validation**: 16 images pour ajuster les param√®tres pendant l'entra√Ænement.
>
> **L'ensemble de test**: 624 images pour √©valuer la performance finale. Il contient 234 images normales et 390 images de pneumonie.
>
> Vous remarquerez que le jeu de donn√©es est d√©s√©quilibr√©: il y a presque 3 fois plus de cas de pneumonie que de cas normaux. Nous avons d√ª en tenir compte dans notre entra√Ænement."

---

## Slide 9: Pr√©paitement des Images

**√Ä LIRE:**

> "Avant d'envoyer les images au r√©seau, nous devons les pr√©parer. Cette √©tape s'appelle le pr√©traitement.
>
> **Redimensionnement**: Toutes les images sont redimensionn√©es √† 224√ó224 pixels, car c'est la taille attendue par ResNet.
>
> **Normalisation**: Les valeurs des pixels sont normalis√©es en utilisant les moyennes et √©carts-types d'ImageNet. Cela standardise les donn√©es et facilite l'apprentissage.
>
> Pour l'entra√Ænement, nous ajoutons aussi de l'augmentation de donn√©es:
>
> **Retournement horizontal**: L'image peut √™tre invers√©e comme un miroir.
>
> **Rotation**: L'image peut √™tre tourn√©e jusqu'√† 15 degr√©s.
>
> **Translation**: L'image peut √™tre l√©g√®rement d√©cal√©e.
>
> **Variation de couleur**: La luminosit√© et le contraste peuvent varier l√©g√®rement.
>
> Ces augmentations cr√©ent artificiellement plus de vari√©t√© dans les donn√©es, ce qui aide le mod√®le √† mieux g√©n√©raliser et √©vite le surapprentissage."

---

# üìñ PARTIE 4: ENTRA√éNEMENT (4-5 minutes)

## Slide 10: Processus d'Entra√Ænement

**√Ä LIRE:**

> "Maintenant, parlons de comment le mod√®le apprend.
>
> L'entra√Ænement se fait en plusieurs 'epochs'. Une epoch, c'est quand le mod√®le a vu toutes les images d'entra√Ænement une fois. Nous avons entra√Æn√© pendant 15 epochs.
>
> √Ä chaque epoch, les images sont divis√©es en 'batches' de 32 images. Pour chaque batch:
>
> **√âtape 1 - Passage avant**: Les images traversent le r√©seau et produisent des pr√©dictions.
>
> **√âtape 2 - Calcul de l'erreur**: On compare les pr√©dictions aux vraies √©tiquettes avec la fonction de perte Binary Cross Entropy. Plus l'erreur est grande, plus le mod√®le s'est tromp√©.
>
> **√âtape 3 - R√©tropropagation**: L'erreur se propage √† rebours dans le r√©seau pour calculer comment chaque poids a contribu√© √† l'erreur.
>
> **√âtape 4 - Mise √† jour**: Les poids sont ajust√©s pour r√©duire l'erreur. Nous utilisons l'optimiseur Adam avec un taux d'apprentissage de 0.001.
>
> Ce processus se r√©p√®te pour chaque batch, puis pour chaque epoch, jusqu'√† ce que le mod√®le converge vers de bonnes performances."

---

## Slide 11: Hyperparam√®tres

**√Ä LIRE:**

> "Les hyperparam√®tres sont les r√©glages que l'on choisit avant l'entra√Ænement. Voici ceux que nous avons utilis√©s:
>
> **Taille des images**: 224√ó224 pixels, standard pour ResNet.
>
> **Taille du batch**: 32 images √† la fois. C'est un bon compromis entre vitesse et stabilit√©.
>
> **Nombre d'epochs**: 15 passages sur les donn√©es.
>
> **Taux d'apprentissage initial**: 0.001, qui diminue automatiquement si le mod√®le stagne.
>
> **Dropout**: 50% et 30% pour la r√©gularisation.
>
> Nous avons aussi utilis√© un planificateur de taux d'apprentissage qui r√©duit le taux par 5 si la perte de validation ne s'am√©liore pas pendant 3 epochs. Cela permet un r√©glage fin du mod√®le vers la fin de l'entra√Ænement."

---

# üìñ PARTIE 5: R√âSULTATS (3-4 minutes)

## Slide 12: M√©triques de Performance

**√Ä LIRE:**

> "Voici les r√©sultats de notre mod√®le sur l'ensemble de test:
>
> **Pr√©cision globale (Accuracy)**: 89.26%. Cela signifie que sur 100 images, le mod√®le en classe correctement 89.
>
> **Pr√©cision (Precision)**: 86.62%. Parmi toutes les images que le mod√®le pr√©dit comme pneumonie, 86.62% le sont vraiment.
>
> **Rappel (Recall)**: 97.95%. C'est notre m√©trique la plus importante! Sur 100 vrais cas de pneumonie, le mod√®le en d√©tecte 98. Nous ne manquons presque aucun cas malade.
>
> **Score F1**: 91.94%. C'est la moyenne harmonique de la pr√©cision et du rappel, donnant une vue √©quilibr√©e.
>
> **AUC**: 0.9683. L'aire sous la courbe ROC est proche de 1, indiquant une excellente capacit√© de discrimination.
>
> Le rappel √©lev√© est crucial en m√©decine: il vaut mieux avoir quelques faux positifs que de manquer de vrais cas de pneumonie."

---

## Slide 13: Matrice de Confusion

**√Ä LIRE:**

> "La matrice de confusion nous montre exactement o√π le mod√®le se trompe.
>
> Sur les 234 images normales:
> - 175 ont √©t√© correctement class√©es comme normales (vrais n√©gatifs)
> - 59 ont √©t√© incorrectement class√©es comme pneumonie (faux positifs)
>
> Sur les 390 images de pneumonie:
> - 382 ont √©t√© correctement d√©tect√©es (vrais positifs)
> - Seulement 8 ont √©t√© manqu√©es (faux n√©gatifs)
>
> Ces 8 cas manqu√©s repr√©sentent seulement 2% des pneumonies. C'est un excellent r√©sultat pour une application m√©dicale."

---

# üìñ PARTIE 6: APPLICATION WEB (3-4 minutes)

## Slide 14: Interface Streamlit

**√Ä LIRE:**

> "Pour rendre notre mod√®le accessible, j'ai cr√©√© une application web avec Streamlit.
>
> Streamlit est un framework Python qui permet de cr√©er des applications web interactives tr√®s facilement. En quelques lignes de code, on peut cr√©er une interface compl√®te.
>
> L'application se compose de:
>
> **Une zone de t√©l√©chargement**: L'utilisateur peut glisser-d√©poser ou s√©lectionner une radiographie.
>
> **L'affichage de l'image**: L'image t√©l√©charg√©e est affich√©e pour confirmation.
>
> **Les r√©sultats**: Le diagnostic (Normal ou Pneumonie) s'affiche avec un code couleur - vert pour normal, rouge pour pneumonie.
>
> **Le score de confiance**: Un pourcentage indique √† quel point le mod√®le est certain de sa pr√©diction.
>
> **La barre lat√©rale**: Elle affiche les performances du mod√®le et un avertissement m√©dical."

---

## Slide 15: Fonctionnement de l'Application

**√Ä LIRE:**

> "Voici ce qui se passe quand vous utilisez l'application:
>
> **√âtape 1**: Au d√©marrage, l'application charge le mod√®le entra√Æn√© en m√©moire. Gr√¢ce au cache de Streamlit, cela ne se fait qu'une seule fois.
>
> **√âtape 2**: Quand vous t√©l√©chargez une image, elle est convertie en format RGB si n√©cessaire.
>
> **√âtape 3**: L'image est redimensionn√©e √† 224√ó224 pixels et normalis√©e exactement comme pendant l'entra√Ænement.
>
> **√âtape 4**: L'image pr√©par√©e passe dans le r√©seau de neurones qui produit une probabilit√© entre 0 et 1.
>
> **√âtape 5**: Si la probabilit√© est sup√©rieure √† 0.5, le diagnostic est 'Pneumonie', sinon c'est 'Normal'.
>
> **√âtape 6**: Les r√©sultats s'affichent instantan√©ment avec le niveau de confiance."

---

# üìñ PARTIE 7: D√âMONSTRATION LIVE (2-3 minutes)

## Slide 16: D√©mo

**√Ä LIRE:**

> "Permettez-moi de vous faire une d√©monstration en direct de l'application.
>
> [Ouvrir l'application sur l'√©cran]
>
> Comme vous pouvez le voir, l'interface est simple et intuitive. Testons avec quelques images..."

**[FAIRE LA D√âMO LIVE]**

---

# üìñ PARTIE 8: CONCLUSION (2 minutes)

## Slide 17: R√©sum√© et Perspectives

**√Ä LIRE:**

> "Pour conclure, ce projet d√©montre comment l'intelligence artificielle peut assister le diagnostic m√©dical.
>
> **Ce que nous avons accompli**:
> - Un mod√®le atteignant 89.26% de pr√©cision
> - Un rappel de 97.95%, minimisant les cas manqu√©s
> - Une application web accessible et facile √† utiliser
>
> **Limites actuelles**:
> - Le mod√®le ne distingue pas entre pneumonie bact√©rienne et virale
> - Il a √©t√© entra√Æn√© uniquement sur des radiographies d'enfants
> - Ce n'est pas un outil de diagnostic officiel
>
> **Am√©liorations futures possibles**:
> - Classification multi-classes pour diff√©rents types de pneumonie
> - Visualisation des zones suspectes avec Grad-CAM
> - Entra√Ænement sur un jeu de donn√©es plus diversifi√©
> - D√©ploiement sur mobile pour les zones rurales
>
> Je vous remercie pour votre attention. Avez-vous des questions?"

---

# üìö ANNEXE: R√âPONSES AUX QUESTIONS POTENTIELLES

## Q: Pourquoi utiliser PyTorch plut√¥t que TensorFlow?

> "PyTorch et TensorFlow sont les deux frameworks d'apprentissage profond les plus populaires. J'ai choisi PyTorch pour sa flexibilit√© et son approche plus 'pythonique'. Il est aussi tr√®s populaire dans la recherche acad√©mique."

## Q: Comment g√©rez-vous le d√©s√©quilibre des classes?

> "Nous utilisons des poids de classe automatiques et l'augmentation de donn√©es. Le fait que nous optimisons pour le rappel plut√¥t que la pr√©cision aide aussi √† ne pas sous-d√©tecter la classe minoritaire."

## Q: Le mod√®le peut-il fonctionner sur un t√©l√©phone?

> "Actuellement non, car PyTorch est assez lourd. Mais on pourrait convertir le mod√®le en TensorFlow Lite ou ONNX pour le d√©ployer sur mobile."

## Q: Quelle est la diff√©rence entre pr√©cision et rappel?

> "La pr√©cision dit: parmi mes pr√©dictions positives, combien sont correctes? Le rappel dit: parmi tous les vrais positifs, combien ai-je d√©tect√©s? En m√©decine, le rappel est crucial car on veut d√©tecter tous les malades."

## Q: Combien de temps a pris l'entra√Ænement?

> "Sur un GPU NVIDIA, environ 30-45 minutes. Sur CPU, cela peut prendre plusieurs heures."

---

**FIN DU SCRIPT**

**Temps total estim√©: 25-30 minutes de pr√©sentation**

---

## LIENS UTILES

- **GitHub:** https://github.com/samidardar/pneumonia-detection-CNN
- **Jeu de donn√©es:** https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
- **D√©ploiement Streamlit:** https://share.streamlit.io
